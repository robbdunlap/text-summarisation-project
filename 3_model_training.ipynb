{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7322412d",
   "metadata": {},
   "source": [
    "# Part 3 - Training (aka *fine-tuning*) a Transformer model\n",
    "\n",
    "In this part we will finally train our very own Transformers model. We saw that the zero-shot model didn't produce great results, and that's probably because the model was trained on summarising news articles, not academic papers. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e04f77",
   "metadata": {},
   "source": [
    "These lines of code are typical setup for Sagemaker, we require them for training jobs: https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-training.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ce3fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IAM role arn used for running training: arn:aws:iam::595714217589:user/Administrator\n",
      "S3 bucket used for storing artifacts: sagemaker-us-east-1-595714217589\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "region = sagemaker.Session().boto_region_name\n",
    "\n",
    "# the \"get_execution_role()\" method doesn't work when running a notebook locally and using the API.\n",
    "# see the explanation in \"0b_data_prep_reviews_corrected.ipynb\" for an explanation and how to get \n",
    "# the proper variable\n",
    "# role = sagemaker.get_execution_role()\n",
    "role = 'arn:aws:iam::595714217589:user/Administrator'\n",
    "\n",
    "print(f\"IAM role arn used for running training: {role}\")\n",
    "print(f\"S3 bucket used for storing artifacts: {bucket}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2b90b",
   "metadata": {},
   "source": [
    "We are in the great position that we don't have to write our own training script. Instead we will use a script from the transformers library in Github: https://github.com/huggingface/transformers/blob/v4.6.1/examples/pytorch/summarization/run_summarization.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0337381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "git_config = {'repo': 'https://github.com/huggingface/transformers.git','branch': 'v4.6.1'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd42fe8",
   "metadata": {},
   "source": [
    "These are the parameters for training, and this is one of the most important levers we can leverage once we are in the experimentation phase. Changing these parameters can influence the model performance and there will be a component of trial & error to find the best model. Also check out https://docs.aws.amazon.com/sagemaker/latest/dg/automatic-model-tuning.html for automated hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ed3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters, which are passed into the training job\n",
    "hyperparameters={'per_device_train_batch_size': 4,\n",
    "                 'per_device_eval_batch_size': 4,\n",
    "                 'model_name_or_path': 'sshleifer/distilbart-cnn-12-6',\n",
    "                 'train_file': '/opt/ml/input/data/datasets/train.csv',\n",
    "                 'validation_file': '/opt/ml/input/data/datasets/val.csv',\n",
    "                 'do_train': True,\n",
    "                 'do_eval': True,\n",
    "                 'do_predict': False,\n",
    "                 'predict_with_generate': True,\n",
    "                 'output_dir': '/opt/ml/model',\n",
    "                 'num_train_epochs': 3,\n",
    "                 'learning_rate': 5e-5,\n",
    "                 'seed': 7,\n",
    "                 'fp16': True,\n",
    "                 'val_max_target_length': 20,\n",
    "                 'text_column': 'text',\n",
    "                 'summary_column': 'summary',\n",
    "                 }\n",
    "\n",
    "# configuration for running training on smdistributed Data Parallel\n",
    "distribution = {'smdistributed':{'dataparallel':{ 'enabled': True }}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086daaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface import HuggingFace\n",
    "\n",
    "# create the Estimator\n",
    "huggingface_estimator = HuggingFace(\n",
    "    entry_point='run_summarization.py',\n",
    "    source_dir='./examples/pytorch/summarization',\n",
    "    git_config=git_config,\n",
    "    instance_type='ml.p3.16xlarge',\n",
    "    instance_count=2,\n",
    "    transformers_version='4.6',\n",
    "    pytorch_version='1.7',\n",
    "    py_version='py36',\n",
    "    role=role,\n",
    "    hyperparameters=hyperparameters,\n",
    "    distribution=distribution,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3150c672",
   "metadata": {},
   "source": [
    "This will kick off the training job which should take around 1 hour. There is also the option to use distributed training with more instances, see here:https://docs.aws.amazon.com/sagemaker/latest/dg/distributed-training.html. Running this training with 2 distributed instances should take ~40 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e51e544b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "huggingface_estimator.fit({'datasets':f's3://{bucket}/summarization/data/'}, wait=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
