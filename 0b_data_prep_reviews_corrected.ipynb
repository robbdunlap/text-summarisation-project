{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85bac51e",
   "metadata": {},
   "source": [
    "# Part 0 - Data preparation\n",
    "\n",
    "In this notebook we will download the arXiv dataset and save it to S3. We will also do some light data preprocessing by only keeping the columns we need, filtering out reviews that are too short, and limiting the size of the datasets.\n",
    "\n",
    "To read more, please check out https://towardsdatascience.com/setting-up-a-text-summarisation-project-introduction-526622eea4a8."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880efb0c",
   "metadata": {},
   "source": [
    "First of all we want to make sure that the relevent libraries are installed on this machine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fe74630",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sagemaker>=2.48.0 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (2.69.0)\n",
      "Collecting sagemaker>=2.48.0\n",
      "  Downloading sagemaker-2.82.2.tar.gz (520 kB)\n",
      "\u001b[K     |████████████████████████████████| 520 kB 6.0 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: transformers==4.6.1 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (4.6.1)\n",
      "Requirement already satisfied: datasets[s3]==1.6.2 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (1.6.2)\n",
      "Requirement already satisfied: sacremoses in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from transformers==4.6.1) (0.0.49)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from transformers==4.6.1) (1.22.3)\n",
      "Requirement already satisfied: packaging in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from transformers==4.6.1) (21.3)\n",
      "Requirement already satisfied: requests in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from transformers==4.6.1) (2.27.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from transformers==4.6.1) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from transformers==4.6.1) (2022.3.15)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from transformers==4.6.1) (4.49.0)\n",
      "Requirement already satisfied: huggingface-hub==0.0.8 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from transformers==4.6.1) (0.0.8)\n",
      "Requirement already satisfied: filelock in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from transformers==4.6.1) (3.6.0)\n",
      "Requirement already satisfied: fsspec in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from datasets[s3]==1.6.2) (2021.7.0)\n",
      "Requirement already satisfied: multiprocess in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from datasets[s3]==1.6.2) (0.70.12.2)\n",
      "Requirement already satisfied: pyarrow>=1.0.0<4.0.0 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from datasets[s3]==1.6.2) (7.0.0)\n",
      "Requirement already satisfied: pandas in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from datasets[s3]==1.6.2) (1.4.1)\n",
      "Requirement already satisfied: dill in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from datasets[s3]==1.6.2) (0.3.4)\n",
      "Requirement already satisfied: xxhash in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from datasets[s3]==1.6.2) (3.0.0)\n",
      "Requirement already satisfied: boto3==1.16.43 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from datasets[s3]==1.6.2) (1.16.43)\n",
      "Requirement already satisfied: s3fs in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from datasets[s3]==1.6.2) (2021.7.0)\n",
      "Requirement already satisfied: botocore==1.19.52 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from datasets[s3]==1.6.2) (1.19.52)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from boto3==1.16.43->datasets[s3]==1.6.2) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from boto3==1.16.43->datasets[s3]==1.6.2) (0.3.7)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from botocore==1.19.52->datasets[s3]==1.6.2) (2.8.2)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.25.4 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from botocore==1.19.52->datasets[s3]==1.6.2) (1.26.8)\n",
      "Collecting attrs==20.3.0\n",
      "  Using cached attrs-20.3.0-py2.py3-none-any.whl (49 kB)\n",
      "Collecting sagemaker>=2.48.0\n",
      "  Downloading sagemaker-2.82.1.tar.gz (520 kB)\n",
      "\u001b[K     |████████████████████████████████| 520 kB 18.9 MB/s eta 0:00:01\n",
      "\u001b[?25h  Downloading sagemaker-2.82.0.tar.gz (520 kB)\n",
      "\u001b[K     |████████████████████████████████| 520 kB 46.1 MB/s eta 0:00:01\n",
      "\u001b[?25h  Using cached sagemaker-2.81.1.tar.gz (519 kB)\n",
      "  Using cached sagemaker-2.81.0.tar.gz (519 kB)\n",
      "  Using cached sagemaker-2.80.0.tar.gz (517 kB)\n",
      "  Using cached sagemaker-2.79.0.tar.gz (516 kB)\n",
      "  Using cached sagemaker-2.78.0.tar.gz (513 kB)\n",
      "  Using cached sagemaker-2.77.1.tar.gz (513 kB)\n",
      "  Using cached sagemaker-2.77.0.tar.gz (513 kB)\n",
      "  Using cached sagemaker-2.76.0.tar.gz (512 kB)\n",
      "  Using cached sagemaker-2.75.1.tar.gz (511 kB)\n",
      "Requirement already satisfied: attrs in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from sagemaker>=2.48.0) (21.4.0)\n",
      "  Using cached sagemaker-2.75.0.tar.gz (511 kB)\n",
      "  Using cached sagemaker-2.74.0.tar.gz (481 kB)\n",
      "  Using cached sagemaker-2.73.0.tar.gz (481 kB)\n",
      "  Using cached sagemaker-2.72.3.tar.gz (475 kB)\n",
      "  Using cached sagemaker-2.72.2.tar.gz (473 kB)\n",
      "  Using cached sagemaker-2.72.1.tar.gz (473 kB)\n",
      "  Using cached sagemaker-2.72.0.tar.gz (477 kB)\n",
      "  Using cached sagemaker-2.71.0.tar.gz (477 kB)\n",
      "  Using cached sagemaker-2.70.0.tar.gz (466 kB)\n",
      "Requirement already satisfied: pathos in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from sagemaker>=2.48.0) (0.2.8)\n",
      "Requirement already satisfied: importlib-metadata>=1.4.0 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from sagemaker>=2.48.0) (4.8.2)\n",
      "Requirement already satisfied: protobuf>=3.1 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from sagemaker>=2.48.0) (3.19.4)\n",
      "Requirement already satisfied: smdebug-rulesconfig==1.0.1 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from sagemaker>=2.48.0) (1.0.1)\n",
      "Requirement already satisfied: protobuf3-to-dict>=0.1.5 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from sagemaker>=2.48.0) (0.1.5)\n",
      "Requirement already satisfied: google-pasta in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from sagemaker>=2.48.0) (0.2.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from importlib-metadata>=1.4.0->sagemaker>=2.48.0) (3.7.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from packaging->transformers==4.6.1) (3.0.4)\n",
      "Requirement already satisfied: six in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from protobuf3-to-dict>=0.1.5->sagemaker>=2.48.0) (1.16.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from requests->transformers==4.6.1) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from requests->transformers==4.6.1) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from requests->transformers==4.6.1) (2.0.4)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from pandas->datasets[s3]==1.6.2) (2021.3)\n",
      "Requirement already satisfied: pox>=0.3.0 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from pathos->sagemaker>=2.48.0) (0.3.0)\n",
      "Requirement already satisfied: ppft>=1.6.6.4 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from pathos->sagemaker>=2.48.0) (1.6.6.4)\n",
      "Requirement already satisfied: aiobotocore>=1.0.1 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from s3fs->datasets[s3]==1.6.2) (1.2.2)\n",
      "Requirement already satisfied: wrapt>=1.10.10 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.14.0)\n",
      "Requirement already satisfied: aioitertools>=0.5.1 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (0.10.0)\n",
      "Requirement already satisfied: aiohttp>=3.3.1 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (3.8.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.7.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (4.0.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.3.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (6.0.2)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from aiohttp>=3.3.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (1.2.0)\n",
      "Requirement already satisfied: typing_extensions>=4.0 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from aioitertools>=0.5.1->aiobotocore>=1.0.1->s3fs->datasets[s3]==1.6.2) (4.1.1)\n",
      "Requirement already satisfied: joblib in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from sacremoses->transformers==4.6.1) (1.1.0)\n",
      "Requirement already satisfied: click in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from sacremoses->transformers==4.6.1) (8.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"sagemaker>=2.48.0\" \"transformers==4.6.1\" \"datasets[s3]==1.6.2\" --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe89716a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge_score in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (0.0.4)\n",
      "Requirement already satisfied: nltk in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from rouge_score) (3.7)\n",
      "Requirement already satisfied: six>=1.14.0 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from rouge_score) (1.16.0)\n",
      "Requirement already satisfied: numpy in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from rouge_score) (1.22.3)\n",
      "Requirement already satisfied: absl-py in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from rouge_score) (1.0.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from nltk->rouge_score) (2022.3.15)\n",
      "Requirement already satisfied: joblib in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from nltk->rouge_score) (1.1.0)\n",
      "Requirement already satisfied: click in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from nltk->rouge_score) (8.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from nltk->rouge_score) (4.49.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install rouge_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74713c30",
   "metadata": {},
   "source": [
    "We will download the dataset directly from the Kaggle website so we need to install the Kaggle Python package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a9749dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kaggle in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (1.5.12)\n",
      "Requirement already satisfied: python-dateutil in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from kaggle) (2.8.2)\n",
      "Requirement already satisfied: six>=1.10 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from kaggle) (1.16.0)\n",
      "Requirement already satisfied: certifi in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from kaggle) (2021.10.8)\n",
      "Requirement already satisfied: python-slugify in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from kaggle) (6.1.1)\n",
      "Requirement already satisfied: requests in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from kaggle) (2.27.1)\n",
      "Requirement already satisfied: urllib3 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from kaggle) (1.26.8)\n",
      "Requirement already satisfied: tqdm in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from kaggle) (4.49.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from python-slugify->kaggle) (1.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from requests->kaggle) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/robbdunlap/opt/anaconda3/envs/text_sum/lib/python3.9/site-packages (from requests->kaggle) (2.0.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92cd6652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/Kaggle/kaggle-api\n",
    "# follow the instruction in the above link to export Kaggle username and key to local environment so you don't \n",
    "# have to put it in the notebook (so it won't be exposed on GitHub)\n",
    "\n",
    "# only run the below if you aren't able to export these to your local environment through your shell\n",
    "# import os\n",
    "# os.environ['KAGGLE_USERNAME'] = \"<your-kaggle-username>\"\n",
    "# os.environ['KAGGLE_KEY'] = \"<your-kaggle-api-key>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "413c346b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import kaggle\n",
    "kaggle.api.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4d7f1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle.api.dataset_download_files('Cornell-University/arxiv', path=\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d2b814a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  arxiv.zip\n",
      "  inflating: arxiv-metadata-oai-snapshot.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip arxiv.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0fd20d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beba5f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir raw_data\n",
    "!mv arxiv.zip raw_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8100b134",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mv arxiv-metadata-oai-snapshot.json raw_data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6dc9f150",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-data_dir=.%2Fraw_data%2F\n",
      "Reusing dataset arxiv_dataset (/Users/robbdunlap/.cache/huggingface/datasets/arxiv_dataset/default-data_dir=.%2Fraw_data%2F/1.1.0/242eb95c95350194872f5be3fb00e7938e53b0944442e85f45a5d2240328f370)\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"arxiv_dataset\", data_dir='./raw_data/', split='train', ignore_verifications=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605aae99",
   "metadata": {},
   "source": [
    "The original dataset is too long, so we shuffle it and limit the number of records to 25,000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f6efedf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached shuffled indices for dataset at /Users/robbdunlap/.cache/huggingface/datasets/arxiv_dataset/default-data_dir=.%2Fraw_data%2F/1.1.0/242eb95c95350194872f5be3fb00e7938e53b0944442e85f45a5d2240328f370/cache-4967dbf59015801c.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['id', 'submitter', 'authors', 'title', 'comments', 'journal-ref', 'doi', 'report-no', 'categories', 'license', 'abstract', 'update_date'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = dataset.shuffle(seed=42)\n",
    "dataset = dataset.select(range(25000))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62c0f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95d41258",
   "metadata": {},
   "outputs": [],
   "source": [
    " # only keep columns that are required\n",
    "df = df[['abstract', 'title']]\n",
    "df = df.rename(columns={\"abstract\": \"text\", \"title\": \"summary\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "45044aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.replace(r'\\n',' ', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "657c2475",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0149280b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The rest-frame UV spectra of three recent tidal disruption events (TDEs), ASASSN-14li, PTF15af...</td>\n",
       "      <td>Carbon and Nitrogen Abundance Ratio In the Broad Line Region of Tidal   Disruption Events</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Inspired by the success of transformer-based pre-training methods on natural language tasks an...</td>\n",
       "      <td>Survey: Transformer based Video-Language Pre-training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pandharipande-Pixton have used the geometry of the moduli space of stable quotients to produce...</td>\n",
       "      <td>Tautological relations in moduli spaces of weighted pointed curves</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Suppose X is a projective toric scheme defined over a commutative ring R equipped with an ampl...</td>\n",
       "      <td>A splitting result for the algebraic K-theory of projective toric   schemes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>We introduce an approach that accurately reconstructs 3D human poses and detailed 3D full-body...</td>\n",
       "      <td>Deep3DPose: Realtime Reconstruction of Arbitrarily Posed Human Bodies   from Single RGB Images</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                  text  \\\n",
       "0    The rest-frame UV spectra of three recent tidal disruption events (TDEs), ASASSN-14li, PTF15af...   \n",
       "1    Inspired by the success of transformer-based pre-training methods on natural language tasks an...   \n",
       "2    Pandharipande-Pixton have used the geometry of the moduli space of stable quotients to produce...   \n",
       "3    Suppose X is a projective toric scheme defined over a commutative ring R equipped with an ampl...   \n",
       "4    We introduce an approach that accurately reconstructs 3D human poses and detailed 3D full-body...   \n",
       "\n",
       "                                                                                          summary  \n",
       "0       Carbon and Nitrogen Abundance Ratio In the Broad Line Region of Tidal   Disruption Events  \n",
       "1                                           Survey: Transformer based Video-Language Pre-training  \n",
       "2                              Tautological relations in moduli spaces of weighted pointed curves  \n",
       "3                     A splitting result for the algebraic K-theory of projective toric   schemes  \n",
       "4  Deep3DPose: Realtime Reconstruction of Arbitrarily Posed Human Bodies   from Single RGB Images  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6c4750",
   "metadata": {},
   "source": [
    "## Filtering the dataset\n",
    "\n",
    "We want to discard reviews and titles that are too short, so that our model can produce more interesting summaries.\n",
    "\n",
    "**How this works**\n",
    "This splits the sentences in both the summary and text columns, selects thoses that are greater than or equal to the minimum cutoff number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53102dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cutoff_summary = 5\n",
    "cutoff_text = 20\n",
    "df = df[(df['summary'].apply(lambda x: len(x.split()) >= cutoff_summary)) & (df['text'].apply(lambda x: len(x.split()) >= cutoff_text))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e0b156d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23719"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0769ad53",
   "metadata": {},
   "source": [
    "## Limiting the size of the datasets and splitting\n",
    "\n",
    "We want to limit the size of the datasets so that training of the model can finish in a reasonable amount of time. This is a decision that we might want to revisit in the experimentation phase if we want to increase the performance of the model. We then split the dataset into test (80%), validation (10%), and test (10%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e5f42ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(20000, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a29b5891",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# split the dataset into train, val, and test\n",
    "df_train, df_val, df_test = np.split(df.sample(frac=1, random_state=44), [int(0.8*len(df)), int((0.9)*len(df))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d4c36f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('data/train.csv', index=False)\n",
    "df_val.to_csv('data/val.csv', index=False)\n",
    "df_test.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98223a6c",
   "metadata": {},
   "source": [
    "## Save the data as CSV files and upload them to S3\n",
    "\n",
    "We need to upload the data to S3 in order to train the model at a later point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf5cab8",
   "metadata": {},
   "source": [
    "## Connecting to AWS\n",
    "For the below to work you'll need to configure your environment to work with AWS, if you don't you'll get **\"ValueError: Must setup local AWS configuration with a region supported by SageMaker.\"** <br> \n",
    "\n",
    "<u>Steps</u>\n",
    "1. Install AWS Command Line Interface (CLI) on your system (https://docs.aws.amazon.com/cli/latest/userguide/getting-started-install.html)\n",
    "(I used Homebrew to install instead of using curl/sudo).\n",
    "2. Create an AWS Identify and Access Management (IAM) profile (https://docs.aws.amazon.com/IAM/latest/UserGuide/getting-started_create-admin-group.html). This is like creating a user account that doesn't have root access on Unix.\n",
    "3. Create access keys for the IAM profile (https://docs.aws.amazon.com/cli/latest/userguide/cli-configure-quickstart.html#cli-configure-quickstart-creds).\n",
    "4. Configure your local environment using the AWS CLI tool (same link as above).\n",
    "\n",
    "_____\n",
    "## I think the below is not necessary\n",
    "The \"role\" variable isn't used but I'm keeping the text to explain how to do it just in case it's needed in subsequent notebooks\n",
    "_____\n",
    "\n",
    "The next problem was a bugger to figure out. The instructional text showed setting the \"role\" variable using:\n",
    "```python\n",
    "role = sagemaker.get_execution_role()\n",
    "```\n",
    "but this doesn't work (it only works in a Jupyter notebook within Sagemaker, not when you're executing code on your local maching and trying to work through the AWS API) (see https://stackoverflow.com/questions/47710558/the-current-aws-identity-is-not-a-role-for-sagemaker). Instead, do the following to create the \"role\" variable:\n",
    "\n",
    "1. go to the IAM dashboard (https://us-east-1.console.aws.amazon.com/iamv2/home#/users).\n",
    "2. Click on \"Users\" in the left-hand side navigation panel.\n",
    "3. Click on the \"User Name\" you created when creating the IAM profile above.\n",
    "4. Copy the \"User ARN\" that is at the top of the \"Summary\" section on the resulting page\n",
    "5. Set the \"role\" variable equal to this value:\n",
    "```python\n",
    "role = arn:aws:iam::123456789:user/IAMaccountname \n",
    "```\n",
    "\n",
    "If this still doesn't work, verify that your gave the IAM account access to S3 by clicking on the \"Access Advisor\" tab in the \"Summary\" section. If the account has access it will have \"Amazon S3\" listed as a service.\n",
    "\n",
    "After having done these step the below code will run properly.\n",
    "\n",
    "**\\*\\*Do not save your role ARN value to GitHub as it probably can be used by an attacker to get access to your account\\*\\***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "54c83b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AWS Region: us-east-1\n",
      "Role Arn: put your ARN info here - as described above\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "bucket = sagemaker.Session().default_bucket()\n",
    "\n",
    "region = sagemaker.Session().boto_region_name\n",
    "print(f\"AWS Region: {region}\")\n",
    "role = 'put your ARN info here - as described above'\n",
    "print(f\"Role Arn: {role}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3ccac070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: data/train.csv to s3://sagemaker-us-east-1-595714217589/summarization/data/train.csv\n",
      "upload: data/val.csv to s3://sagemaker-us-east-1-595714217589/summarization/data/val.csv\n",
      "upload: data/test.csv to s3://sagemaker-us-east-1-595714217589/summarization/data/test.csv\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp data/train.csv s3://$bucket/summarization/data/train.csv\n",
    "!aws s3 cp data/val.csv s3://$bucket/summarization/data/val.csv\n",
    "!aws s3 cp data/test.csv s3://$bucket/summarization/data/test.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
